{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSZgmKc1gCBQ",
        "outputId": "50a115c3-65f5-42c4-82f7-b1a61d9fb737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': \"Extract the product information:\\n<div class='product'><h2>iPad Air</h2><span class='price'>$1344</span><span class='category'>audio</span><span class='brand'>Dell</span></div>\", 'output': {'name': 'iPad Air', 'price': '$1344', 'category': 'audio', 'manufacturer': 'Dell'}}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "file = json.load(open(\"1_product_dataset.json\", \"r\"))\n",
        "print(file[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tol-YwEvhkNx",
        "outputId": "9d9291ab-a4c9-4e08-939c-15eb97224f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping unsloth as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting unsloth\n",
            "  Downloading unsloth-2025.3.3-py3-none-any.whl.metadata (59 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.19.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.9.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting unsloth_zoo>=2025.3.1 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.31.post1.tar.gz (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: packaging in /Users/eyobgemechu/repos/ai-projects/.venv/lib/python3.13/site-packages (from unsloth) (25.0)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.26-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n",
            "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting datasets>=2.16.0 (from unsloth)\n",
            "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
            "  Downloading sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tqdm (from unsloth)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: psutil in /Users/eyobgemechu/repos/ai-projects/.venv/lib/python3.13/site-packages (from unsloth) (7.0.0)\n",
            "Collecting wheel>=0.42.0 (from unsloth)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting numpy (from unsloth)\n",
            "  Using cached numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting huggingface_hub (from unsloth)\n",
            "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
            "Collecting diffusers (from unsloth)\n",
            "  Downloading diffusers-0.34.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.22.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
            "Collecting pyyaml (from peft)\n",
            "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting safetensors (from peft)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting scipy (from bitsandbytes)\n",
            "  Using cached scipy-1.16.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
            "Collecting filelock (from datasets>=2.16.0->unsloth)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets>=2.16.0->unsloth)\n",
            "  Downloading pandas-2.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Collecting requests>=2.32.2 (from datasets>=2.16.0->unsloth)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
            "  Downloading xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n",
            "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub->unsloth)\n",
            "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
            "Collecting setuptools (from torch>=2.4.0->unsloth)\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.4.0->unsloth)\n",
            "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=2.4.0->unsloth)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers!=4.47.0,>=4.46.1->unsloth)\n",
            "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers!=4.47.0,>=4.46.1->unsloth)\n",
            "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.1->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pillow (from unsloth_zoo>=2025.3.1->unsloth)\n",
            "  Downloading pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
            "Collecting importlib_metadata (from diffusers->unsloth)\n",
            "  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
            "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting rich>=11.1.0 (from tyro->unsloth)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
            "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached aiohttp-3.12.14-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets>=2.16.0->unsloth)\n",
            "  Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets>=2.16.0->unsloth)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets>=2.16.0->unsloth)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets>=2.16.0->unsloth)\n",
            "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/eyobgemechu/repos/ai-projects/.venv/lib/python3.13/site-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.4.0->unsloth)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting zipp>=3.20 (from importlib_metadata->diffusers->unsloth)\n",
            "  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.4.0->unsloth)\n",
            "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/eyobgemechu/repos/ai-projects/.venv/lib/python3.13/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets>=2.16.0->unsloth)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets>=2.16.0->unsloth)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached multidict-6.6.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (73 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/eyobgemechu/repos/ai-projects/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Downloading unsloth-2025.3.3-py3-none-any.whl (190 kB)\n",
            "Downloading trl-0.19.1-py3-none-any.whl (376 kB)\n",
            "Downloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
            "Downloading accelerate-1.9.0-py3-none-any.whl (367 kB)\n",
            "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
            "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
            "Using cached numpy-2.3.1-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
            "Using cached torch-2.7.1-cp313-none-macosx_11_0_arm64.whl (68.6 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.3.1-py3-none-any.whl (110 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Downloading diffusers-0.34.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached scipy-1.16.0-cp313-cp313-macosx_14_0_arm64.whl (20.7 MB)\n",
            "Downloading torchvision-0.22.1-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.26-py3-none-any.whl (128 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
            "Downloading pillow-11.3.0-cp313-cp313-macosx_11_0_arm64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp313-cp313-macosx_12_0_arm64.whl (31.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
            "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
            "Downloading pandas-2.3.1-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading xxhash-3.5.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\n",
            "Using cached aiohttp-3.12.14-cp313-cp313-macosx_11_0_arm64.whl (465 kB)\n",
            "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl (199 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.7.0-cp313-cp313-macosx_11_0_arm64.whl (45 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached multidict-6.6.3-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached propcache-0.3.2-cp313-cp313-macosx_11_0_arm64.whl (41 kB)\n",
            "Using cached yarl-1.20.1-cp313-cp313-macosx_11_0_arm64.whl (88 kB)\n",
            "Building wheels for collected packages: sentencepiece, xformers\n",
            "  Building wheel for sentencepiece (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sentencepiece: filename=sentencepiece-0.2.0-cp313-cp313-macosx_10_13_universal2.whl size=1290445 sha256=a2ba86df8764286f53749f3c022579dff6f39e4a9faa322ebf069472b97c6156\n",
            "  Stored in directory: /Users/eyobgemechu/Library/Caches/pip/wheels/02/3d/f0/8dbb11925fbd58340b128ae9334ae7028332d7a5751738f616\n",
            "  Building wheel for xformers (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for xformers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[215 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m /private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-build-env-3vxh0pv0/overlay/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
            "  \u001b[31m   \u001b[0m   cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
            "  \u001b[31m   \u001b[0m /private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-build-env-3vxh0pv0/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         License :: OSI Approved :: BSD License\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
            "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m !!\n",
            "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m /private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-build-env-3vxh0pv0/overlay/lib/python3.13/site-packages/torch/utils/cpp_extension.py:576: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_deprecation_warning.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/attn_bias_utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/checkpoint.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/test.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_cpp_lib.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m copying xformers/info.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/importing.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/vararg_kernel.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/triton/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/flash_attn_3\n",
            "  \u001b[31m   \u001b[0m copying xformers/flash_attn_3/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/flash_attn_3\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/residual.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/input_projection.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/rmsnorm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/modpar_layers.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/swiglu_op.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/unbind.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/rope_padded.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/seqpar.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/sp24.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/tree_attention.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/common.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/tiled_matmul.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/indexing.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/device_limits.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/find_slowest.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/api.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profile_analyzer.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/profiler\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/_csr_ops.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m copying xformers/sparse/csr_tensor.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/sparse\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/fused_softmax.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/core.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_mask.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m copying xformers/components/attention/base.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/components/attention\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/benchmarks/LRA/code\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/matmul_perf_model.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/_triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash3.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/common.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_decoder.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/ops/fmha/_triton\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/losses\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/layers\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_split.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fp8.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_fa.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_onekernel.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/test.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bench.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/utils.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/train.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill_fused.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/flash_attn_triton_amd\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/library.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/testing.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/torch.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/utils\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/models\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/modules\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-10.13-universal2-cpython-313/xformers/_flash_attn/ops/triton\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m building 'xformers._C' extension\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/attention\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/attention/autograd\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/attention/cpu\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/sparse24\n",
            "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/swiglu\n",
            "  \u001b[31m   \u001b[0m clang++ -fno-strict-overflow -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -O3 -Wall -arch arm64 -arch x86_64 -I/private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-install-jharm_k7/xformers_b9376c74d5054f4aac36c897dd96e5f6/xformers/csrc -I/private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-build-env-3vxh0pv0/overlay/lib/python3.13/site-packages/torch/include -I/private/var/folders/3x/6fbccp_96f11_dwh7x34t17h0000gn/T/pip-build-env-3vxh0pv0/overlay/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -I/Users/eyobgemechu/repos/ai-projects/.venv/include -I/Library/Frameworks/Python.framework/Versions/3.13/include/python3.13 -c xformers/csrc/attention/attention.cpp -o build/temp.macosx-10.13-universal2-cpython-313/xformers/csrc/attention/attention.o -O3 -std=c++17 -DPy_LIMITED_API=0x03090000 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPy_LIMITED_API=0x03090000 -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "  \u001b[31m   \u001b[0m clang++: error: unsupported option '-fopenmp'\n",
            "  \u001b[31m   \u001b[0m clang++: error: unsupported option '-fopenmp'\n",
            "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built sentencepiece\n",
            "Failed to build xformers\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y unsloth peft\n",
        "!pip install unsloth trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlKkBZPUix0S",
        "outputId": "f811e1c6-6f39-41fb-df5b-67a781dd1177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "a7d0373ebb594da6bb0090ce9f97abd3",
            "0a40f35d2c434e01bfb29e1b3b4161b8",
            "c22c10617d6345b8ac4de9f1c0ca92b0",
            "e3b0b74d17814371a4e0114d121bb4d4",
            "a47805b3ef8d472daf686518b8965471",
            "59c4860dd94f436ea9dbd19ae108a24c",
            "08d0f4a0a8b1420396046b346fa21bc9",
            "86321d3aa29f49f48483ba8beb51ccfe",
            "a481fbd3e52e47e0bcc036e6db6af31d",
            "0bb37bb4125d433f89fc953e1491a7b5",
            "16594f1eb1bc447d9eecd28c705d26b0",
            "4c2669ff9d4d42a7942ecc0997c47897",
            "d6033bc5df1b4f3ebc5d16b45a7a944f",
            "c5a255e4a81445ffbacfcbda64210b9d",
            "31151f447afe46cfbd77adf8b635b26d",
            "271d33b2f39a40bdb5c3e16ecdcd337e",
            "ed5f2141304243a5857aef0c2d0c3198",
            "0047effbca2b4d7d9a19265b522035d9",
            "e6a1b392f2b84e8a80eb27d273191432",
            "2ecf0607c2f847b49b0356d17218ba8e",
            "34c024f8b7e744d3b25518b61d15921a",
            "4a9fcc7a6cde41e18dd5557e09d402f6",
            "23319077241a4b1f845a90e16ea00201",
            "6cf74a3fb2634c2bbc160846ba3df755",
            "35e07fbd4fd546cab0f1374a7f05ce9e",
            "9f8cd4300349419090114e01efa69b69",
            "f9003471a3244da996b20b5c2775438c",
            "3219b3ebded0408485a3f135d796aa50",
            "e3bd4c27b9d1459a86704dc0abaa2d96",
            "a2ab6daf503e44cdabd93e9c773feefa",
            "9f275375afa24b088301180e688c2619",
            "95350774fe364ccb8cd84305723853bc",
            "3c5dac4b8b54497f9f5bbd7e94c49403",
            "59809082c9894a679d5f901f2d5688ec",
            "771acfe04331495682ad08061cc20cbc",
            "68c44d2fe3c44423a7f800b7cc49ddbc",
            "55f166f6c6ab456b919816c3ed6720ff",
            "de60af6686a941c3b30c990fb95218b9",
            "d393da78b51a4476b58e45e619588163",
            "5dc7898458bf4b66bad4b50d0537be96",
            "077be1cc0d044573b8a1ceabf17796fa",
            "c10aa05df129476f92c0a9dc85a504a9",
            "59d40ed5afe44d9b9d176dde8cde7915",
            "731307885d4449a1895a1ada2d026a2f",
            "c51a8ff1bcc04ab587c2ab4427609284",
            "b273b629e4164c9e98b8dd13245d7819",
            "fbe26772d4b54273a9b0902f12156d1e",
            "f9f6be75ec5047078270217889d69697",
            "51b756143daa4fc8a40fefb2fbf5c579",
            "913d0f02ac9c4795ae73a88c2f4a5e46",
            "ee5bb41e2a774b08a73e402d41c64501",
            "26c9759b84d841c993cc2f9119e4e078",
            "dfc7afabbeb44e9fb506317c48d91fb6",
            "8f841f3bc30f40b6b293124ad365473b",
            "5c6fd9a493bd452faed1af7e6305cfcf",
            "c990fb6334594cf8aabbb11a872eaccd",
            "5571a58a83f047ca8706fc7dae762de6",
            "d6cbe4647f0442aea3a31952a39170cf",
            "b61c44963d574e0698320c30a4475b43",
            "e84d4bfdb8744d079e87dcbf33a161f5",
            "d1dd223630d640668304506b601dc191",
            "2c9a3fed5c764c71aed491f2e0f70891",
            "d2eb26e73a084774b78880d8f6f6b225",
            "b9eb1ea1121e47b1bcf7a0955db0e213",
            "17f05f1b15bd4a9dab583051424d6070",
            "352c8c914888495da4cdab12e5ad94bc",
            "ac2d69cd8d914a019bd3f90e2860b57a",
            "f1b77faf7f824cdf9d3f3089d687a295",
            "abebca1de90a4786873e24d44a68973f",
            "d8f86b17d4fa426784fbb22486482468",
            "fba15809082642bcaea1ec2bc864bc28",
            "5242e1b3584f435d9f6e3b5ca187e0db",
            "56723518344b43f7bbb45be6eac4c2aa",
            "e98f4511f4e143a4b21abbb3612383cd",
            "9050f591069c4d5080b0733b23ceee85",
            "ef39ca74b7bc4c79bed00d3ca06867d9",
            "3c02bbb5d1064e2a9a7069db91bbe0d4"
          ]
        },
        "id": "GDfN9RzrjKS4",
        "outputId": "6bfce4af-f2e4-4aab-e6c3-37f3b42497fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.7.5: Fast Mistral patching. Transformers: 4.53.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/quantizers/auto.py:222: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7d0373ebb594da6bb0090ce9f97abd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c2669ff9d4d42a7942ecc0997c47897",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/194 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23319077241a4b1f845a90e16ea00201",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59809082c9894a679d5f901f2d5688ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c51a8ff1bcc04ab587c2ab4427609284",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c990fb6334594cf8aabbb11a872eaccd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/458 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac2d69cd8d914a019bd3f90e2860b57a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model_name=\"unsloth/Phi-3-mini-4k-instruct-bnb-4bit\"\n",
        "\n",
        "max_seq_length = 2048 # Choose sequence length\n",
        "dtype = None # Auto detection\n",
        "\n",
        "# Load model and tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cDiV9bBtkaOZ"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def format_prompt(example):\n",
        "    return f\"### Input: {example['input']}\\n### Output: {json.dumps(example['output'])}<|endoftext|>\"\n",
        "\n",
        "formatted_data = [format_prompt(item) for item in file]\n",
        "dataset = Dataset.from_dict({\"text\": formatted_data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eORGMmDOle-3",
        "outputId": "8fc0a4a4-87a8-4a0a-a864-f45949965df4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.7.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# Add LoRA adapters\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=64,  # LoRA rank - higher = more capacity, more memory\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=128,  # LoRA scaling factor (usually 2x rank)\n",
        "    lora_dropout=0,  # Supports any, but = 0 is optimized\n",
        "    bias=\"none\",     # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth's optimized version\n",
        "    random_state=3407,\n",
        "    use_rslora=False,  # Rank stabilized LoRA\n",
        "    loftq_config=None, # LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "7db615bd5a544ee78013e8643ce5b673",
            "0bb14fc5a52940f1b84ed92d11e995f7",
            "b3fc0a08a2e041f08487e0c31dc82833",
            "0d0aa89d883047e59ce3a1741d0a2791",
            "7a14088f50dc4bfd9152a28f11777d2c",
            "8fc9dde3d0074b37ba38eefe2ec98775",
            "2798c28e27624eab8510d8c94663951e",
            "8a7067d98f9d4453aa40aba765495d0a",
            "e9d323bb7829485a969064225d369166",
            "7e12b91c24814bf5a4e376b2f383fc58",
            "6c275b0e3e364fe592a7fbcefceef31b"
          ]
        },
        "id": "05wxH2ZonUi7",
        "outputId": "05be7190-0c7a-42cb-e2e2-5c67b52c115d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7db615bd5a544ee78013e8643ce5b673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Training arguments optimized for Unsloth\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,  # Effective batch size = 8\n",
        "        warmup_steps=10,\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=25,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        save_strategy=\"epoch\",\n",
        "        save_total_limit=2,\n",
        "        dataloader_pin_memory=False,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "ozwCn1tIrkcy",
        "outputId": "c8b2eee1-b622-410a-c2c9-907ddebff709"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 500 | Num Epochs = 3 | Total steps = 189\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 119,537,664 of 3,940,617,216 (3.03% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgemechueyob87\u001b[0m (\u001b[33mgemechueyob87-na\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250719_221030-ug0lioy2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gemechueyob87-na/huggingface/runs/ug0lioy2' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/gemechueyob87-na/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gemechueyob87-na/huggingface' target=\"_blank\">https://wandb.ai/gemechueyob87-na/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gemechueyob87-na/huggingface/runs/ug0lioy2' target=\"_blank\">https://wandb.ai/gemechueyob87-na/huggingface/runs/ug0lioy2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [189/189 08:08, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.449200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYKe03ExSgW",
        "outputId": "cd994e6b-826b-4e39-c27f-d05aea5f6b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"<|user|> Extract the product information:\\n<div class='product'><h2>Asus ROG Strix</h2><span class='price'>$1106</span><span class='category'>electronics</span><span class='brand'>Amazon</span></div><|end|><|assistant|></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span\"]\n"
          ]
        }
      ],
      "source": [
        "# Test the fine-tuned model\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# Test prompt\n",
        "messages = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"Extract the product information:\\n<div class='product'><h2>Asus ROG Strix</h2><span class='price'>$1106</span><span class='category'>electronics</span><span class='brand'>Amazon</span></div>\"},\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate response\n",
        "outputs = model.generate(\n",
        "    input_ids=inputs,\n",
        "    max_new_tokens=256,\n",
        "    use_cache=True,\n",
        "    temperature=0.7,\n",
        "    do_sample=True,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "# Decode and print\n",
        "response = tokenizer.batch_decode(outputs)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW9pD2AqyjxI",
        "outputId": "e7823dc6-ddb0-4340-9494-1b804f4d2f5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 2.3G\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 6.52 out of 12.67 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:01<00:00, 20.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving gguf_model/pytorch_model-00001-of-00002.bin...\n",
            "Unsloth: Saving gguf_model/pytorch_model-00002-of-00002.bin...\n",
            "Done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Converting mistral model. Can use fast conversion = True.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at gguf_model into f16 GGUF format.\n",
            "The output location will be /content/gguf_model/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Extending gguf_model/tokenizer.model with added_tokens.json.\n",
            "Originally tokenizer.model is of size (32000).\n",
            "But we need to extend to sentencepiece vocab size (32011).\n",
            "/usr/lib/python3.11/subprocess.py:1016: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:hf-to-gguf:Loading model: gguf_model\n",
            "INFO:hf-to-gguf:Model architecture: MistralForCausalLM\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {3072, 32064}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {3072, 3072}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {3072, 8192}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 3072}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {3072}\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {3072, 32064}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 4096\n",
            "INFO:hf-to-gguf:gguf: embedding length = 3072\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 32\n",
            "INFO:hf-to-gguf:gguf: rope theta = 10000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 32000\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 32009\n",
            "INFO:gguf.vocab:Setting add_bos_token to False\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% elif message['role'] == 'user' %}{{'<|user|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>\n",
            "' + message['content'] + '<|end|>\n",
            "'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>\n",
            "' }}{% else %}{{ eos_token }}{% endif %}\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/gguf_model/unsloth.F16.gguf: n_tensors = 291, total_size = 7.6G\n",
            "Writing: 100%|██████████| 7.64G/7.64G [01:47<00:00, 70.9Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/gguf_model/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/gguf_model/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 5944 (36c15324)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/gguf_model/unsloth.F16.gguf' to '/content/gguf_model/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 31 key-value pairs and 291 tensors from /content/gguf_model/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gguf_Model\n",
            "llama_model_loader: - kv   3:                         general.size_label str              = 3.8B\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 3072\n",
            "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 96\n",
            "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 96\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 32064\n",
            "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 96\n",
            "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,32064]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  21:                      tokenizer.ggml.scores arr[f32,32064]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,32064]   = [3, 3, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  25:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  26:            tokenizer.ggml.padding_token_id u32              = 32009\n",
            "llama_model_loader: - kv  27:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  28:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
            "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 3072, 32064,     1,     1], type =    f16, converting to q6_K .. size =   187.88 MiB ->    77.06 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 3072, 32064,     1,     1], type =    f16, converting to q4_K .. size =   187.88 MiB ->    52.84 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 3072,  8192,     1,     1], type =    f16, converting to q4_K .. size =    48.00 MiB ->    13.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 3072,     1,     1,     1], type =    f32, size =    0.012 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q4_K .. size =    18.00 MiB ->     5.06 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 3072,  3072,     1,     1], type =    f16, converting to q6_K .. size =    18.00 MiB ->     7.38 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [ 8192,  3072,     1,     1], type =    f16, converting to q6_K .. size =    48.00 MiB ->    19.69 MiB\n"
          ]
        }
      ],
      "source": [
        "model.save_pretrained_gguf(\"gguf_model\", tokenizer, quantization_method=\"q4_k_m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-dL-_yVym-1"
      },
      "outputs": [],
      "source": [
        "gguf_files = [f for f in os.listdir(\"gguf_model\") if f.endswith(\".gguf\")]\n",
        "if gguf_files:\n",
        "    gguf_file = os.path.join(\"gguf_model\", gguf_files[0])\n",
        "    print(f\"Downloading: {gguf_file}\")\n",
        "    files.download(gguf_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0047effbca2b4d7d9a19265b522035d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077be1cc0d044573b8a1ceabf17796fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d0f4a0a8b1420396046b346fa21bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a40f35d2c434e01bfb29e1b3b4161b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c4860dd94f436ea9dbd19ae108a24c",
            "placeholder": "​",
            "style": "IPY_MODEL_08d0f4a0a8b1420396046b346fa21bc9",
            "value": "model.safetensors: 100%"
          }
        },
        "0bb14fc5a52940f1b84ed92d11e995f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc9dde3d0074b37ba38eefe2ec98775",
            "placeholder": "​",
            "style": "IPY_MODEL_2798c28e27624eab8510d8c94663951e",
            "value": "Unsloth: Tokenizing [&quot;text&quot;]: 100%"
          }
        },
        "0bb37bb4125d433f89fc953e1491a7b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0aa89d883047e59ce3a1741d0a2791": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e12b91c24814bf5a4e376b2f383fc58",
            "placeholder": "​",
            "style": "IPY_MODEL_6c275b0e3e364fe592a7fbcefceef31b",
            "value": " 500/500 [00:00&lt;00:00, 3625.81 examples/s]"
          }
        },
        "16594f1eb1bc447d9eecd28c705d26b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17f05f1b15bd4a9dab583051424d6070": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23319077241a4b1f845a90e16ea00201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cf74a3fb2634c2bbc160846ba3df755",
              "IPY_MODEL_35e07fbd4fd546cab0f1374a7f05ce9e",
              "IPY_MODEL_9f8cd4300349419090114e01efa69b69"
            ],
            "layout": "IPY_MODEL_f9003471a3244da996b20b5c2775438c"
          }
        },
        "26c9759b84d841c993cc2f9119e4e078": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "271d33b2f39a40bdb5c3e16ecdcd337e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2798c28e27624eab8510d8c94663951e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9a3fed5c764c71aed491f2e0f70891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ecf0607c2f847b49b0356d17218ba8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31151f447afe46cfbd77adf8b635b26d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c024f8b7e744d3b25518b61d15921a",
            "placeholder": "​",
            "style": "IPY_MODEL_4a9fcc7a6cde41e18dd5557e09d402f6",
            "value": " 194/194 [00:00&lt;00:00, 15.7kB/s]"
          }
        },
        "3219b3ebded0408485a3f135d796aa50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34c024f8b7e744d3b25518b61d15921a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352c8c914888495da4cdab12e5ad94bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e07fbd4fd546cab0f1374a7f05ce9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ab6daf503e44cdabd93e9c773feefa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f275375afa24b088301180e688c2619",
            "value": 1
          }
        },
        "3c02bbb5d1064e2a9a7069db91bbe0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c5dac4b8b54497f9f5bbd7e94c49403": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a9fcc7a6cde41e18dd5557e09d402f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c2669ff9d4d42a7942ecc0997c47897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6033bc5df1b4f3ebc5d16b45a7a944f",
              "IPY_MODEL_c5a255e4a81445ffbacfcbda64210b9d",
              "IPY_MODEL_31151f447afe46cfbd77adf8b635b26d"
            ],
            "layout": "IPY_MODEL_271d33b2f39a40bdb5c3e16ecdcd337e"
          }
        },
        "51b756143daa4fc8a40fefb2fbf5c579": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5242e1b3584f435d9f6e3b5ca187e0db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5571a58a83f047ca8706fc7dae762de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1dd223630d640668304506b601dc191",
            "placeholder": "​",
            "style": "IPY_MODEL_2c9a3fed5c764c71aed491f2e0f70891",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "55f166f6c6ab456b919816c3ed6720ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59d40ed5afe44d9b9d176dde8cde7915",
            "placeholder": "​",
            "style": "IPY_MODEL_731307885d4449a1895a1ada2d026a2f",
            "value": " 500k/500k [00:00&lt;00:00, 1.13MB/s]"
          }
        },
        "56723518344b43f7bbb45be6eac4c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59809082c9894a679d5f901f2d5688ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_771acfe04331495682ad08061cc20cbc",
              "IPY_MODEL_68c44d2fe3c44423a7f800b7cc49ddbc",
              "IPY_MODEL_55f166f6c6ab456b919816c3ed6720ff"
            ],
            "layout": "IPY_MODEL_de60af6686a941c3b30c990fb95218b9"
          }
        },
        "59c4860dd94f436ea9dbd19ae108a24c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d40ed5afe44d9b9d176dde8cde7915": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6fd9a493bd452faed1af7e6305cfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc7898458bf4b66bad4b50d0537be96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68c44d2fe3c44423a7f800b7cc49ddbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077be1cc0d044573b8a1ceabf17796fa",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c10aa05df129476f92c0a9dc85a504a9",
            "value": 499723
          }
        },
        "6c275b0e3e364fe592a7fbcefceef31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cf74a3fb2634c2bbc160846ba3df755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3219b3ebded0408485a3f135d796aa50",
            "placeholder": "​",
            "style": "IPY_MODEL_e3bd4c27b9d1459a86704dc0abaa2d96",
            "value": "tokenizer_config.json: "
          }
        },
        "731307885d4449a1895a1ada2d026a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771acfe04331495682ad08061cc20cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d393da78b51a4476b58e45e619588163",
            "placeholder": "​",
            "style": "IPY_MODEL_5dc7898458bf4b66bad4b50d0537be96",
            "value": "tokenizer.model: 100%"
          }
        },
        "7a14088f50dc4bfd9152a28f11777d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db615bd5a544ee78013e8643ce5b673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bb14fc5a52940f1b84ed92d11e995f7",
              "IPY_MODEL_b3fc0a08a2e041f08487e0c31dc82833",
              "IPY_MODEL_0d0aa89d883047e59ce3a1741d0a2791"
            ],
            "layout": "IPY_MODEL_7a14088f50dc4bfd9152a28f11777d2c"
          }
        },
        "7e12b91c24814bf5a4e376b2f383fc58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86321d3aa29f49f48483ba8beb51ccfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7067d98f9d4453aa40aba765495d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f841f3bc30f40b6b293124ad365473b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc9dde3d0074b37ba38eefe2ec98775": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9050f591069c4d5080b0733b23ceee85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "913d0f02ac9c4795ae73a88c2f4a5e46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95350774fe364ccb8cd84305723853bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f275375afa24b088301180e688c2619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f8cd4300349419090114e01efa69b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95350774fe364ccb8cd84305723853bc",
            "placeholder": "​",
            "style": "IPY_MODEL_3c5dac4b8b54497f9f5bbd7e94c49403",
            "value": " 3.34k/? [00:00&lt;00:00, 317kB/s]"
          }
        },
        "a2ab6daf503e44cdabd93e9c773feefa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a47805b3ef8d472daf686518b8965471": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a481fbd3e52e47e0bcc036e6db6af31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7d0373ebb594da6bb0090ce9f97abd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a40f35d2c434e01bfb29e1b3b4161b8",
              "IPY_MODEL_c22c10617d6345b8ac4de9f1c0ca92b0",
              "IPY_MODEL_e3b0b74d17814371a4e0114d121bb4d4"
            ],
            "layout": "IPY_MODEL_a47805b3ef8d472daf686518b8965471"
          }
        },
        "abebca1de90a4786873e24d44a68973f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98f4511f4e143a4b21abbb3612383cd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9050f591069c4d5080b0733b23ceee85",
            "value": 1
          }
        },
        "ac2d69cd8d914a019bd3f90e2860b57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1b77faf7f824cdf9d3f3089d687a295",
              "IPY_MODEL_abebca1de90a4786873e24d44a68973f",
              "IPY_MODEL_d8f86b17d4fa426784fbb22486482468"
            ],
            "layout": "IPY_MODEL_fba15809082642bcaea1ec2bc864bc28"
          }
        },
        "b273b629e4164c9e98b8dd13245d7819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913d0f02ac9c4795ae73a88c2f4a5e46",
            "placeholder": "​",
            "style": "IPY_MODEL_ee5bb41e2a774b08a73e402d41c64501",
            "value": "added_tokens.json: 100%"
          }
        },
        "b3fc0a08a2e041f08487e0c31dc82833": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a7067d98f9d4453aa40aba765495d0a",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9d323bb7829485a969064225d369166",
            "value": 500
          }
        },
        "b61c44963d574e0698320c30a4475b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f05f1b15bd4a9dab583051424d6070",
            "placeholder": "​",
            "style": "IPY_MODEL_352c8c914888495da4cdab12e5ad94bc",
            "value": " 458/458 [00:00&lt;00:00, 39.1kB/s]"
          }
        },
        "b9eb1ea1121e47b1bcf7a0955db0e213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c10aa05df129476f92c0a9dc85a504a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c22c10617d6345b8ac4de9f1c0ca92b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86321d3aa29f49f48483ba8beb51ccfe",
            "max": 2264298471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a481fbd3e52e47e0bcc036e6db6af31d",
            "value": 2264298471
          }
        },
        "c51a8ff1bcc04ab587c2ab4427609284": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b273b629e4164c9e98b8dd13245d7819",
              "IPY_MODEL_fbe26772d4b54273a9b0902f12156d1e",
              "IPY_MODEL_f9f6be75ec5047078270217889d69697"
            ],
            "layout": "IPY_MODEL_51b756143daa4fc8a40fefb2fbf5c579"
          }
        },
        "c5a255e4a81445ffbacfcbda64210b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a1b392f2b84e8a80eb27d273191432",
            "max": 194,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ecf0607c2f847b49b0356d17218ba8e",
            "value": 194
          }
        },
        "c990fb6334594cf8aabbb11a872eaccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5571a58a83f047ca8706fc7dae762de6",
              "IPY_MODEL_d6cbe4647f0442aea3a31952a39170cf",
              "IPY_MODEL_b61c44963d574e0698320c30a4475b43"
            ],
            "layout": "IPY_MODEL_e84d4bfdb8744d079e87dcbf33a161f5"
          }
        },
        "d1dd223630d640668304506b601dc191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2eb26e73a084774b78880d8f6f6b225": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d393da78b51a4476b58e45e619588163": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6033bc5df1b4f3ebc5d16b45a7a944f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5f2141304243a5857aef0c2d0c3198",
            "placeholder": "​",
            "style": "IPY_MODEL_0047effbca2b4d7d9a19265b522035d9",
            "value": "generation_config.json: 100%"
          }
        },
        "d6cbe4647f0442aea3a31952a39170cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2eb26e73a084774b78880d8f6f6b225",
            "max": 458,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9eb1ea1121e47b1bcf7a0955db0e213",
            "value": 458
          }
        },
        "d8f86b17d4fa426784fbb22486482468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef39ca74b7bc4c79bed00d3ca06867d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3c02bbb5d1064e2a9a7069db91bbe0d4",
            "value": " 1.84M/? [00:00&lt;00:00, 28.1MB/s]"
          }
        },
        "de60af6686a941c3b30c990fb95218b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc7afabbeb44e9fb506317c48d91fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3b0b74d17814371a4e0114d121bb4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb37bb4125d433f89fc953e1491a7b5",
            "placeholder": "​",
            "style": "IPY_MODEL_16594f1eb1bc447d9eecd28c705d26b0",
            "value": " 2.26G/2.26G [00:17&lt;00:00, 209MB/s]"
          }
        },
        "e3bd4c27b9d1459a86704dc0abaa2d96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a1b392f2b84e8a80eb27d273191432": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84d4bfdb8744d079e87dcbf33a161f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98f4511f4e143a4b21abbb3612383cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e9d323bb7829485a969064225d369166": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed5f2141304243a5857aef0c2d0c3198": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee5bb41e2a774b08a73e402d41c64501": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef39ca74b7bc4c79bed00d3ca06867d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b77faf7f824cdf9d3f3089d687a295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5242e1b3584f435d9f6e3b5ca187e0db",
            "placeholder": "​",
            "style": "IPY_MODEL_56723518344b43f7bbb45be6eac4c2aa",
            "value": "tokenizer.json: "
          }
        },
        "f9003471a3244da996b20b5c2775438c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9f6be75ec5047078270217889d69697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f841f3bc30f40b6b293124ad365473b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6fd9a493bd452faed1af7e6305cfcf",
            "value": " 293/293 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "fba15809082642bcaea1ec2bc864bc28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe26772d4b54273a9b0902f12156d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26c9759b84d841c993cc2f9119e4e078",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfc7afabbeb44e9fb506317c48d91fb6",
            "value": 293
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
